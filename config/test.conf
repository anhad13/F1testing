//include defaults config
include "defaults.conf"

elmo = 0
bidirectional = 0
pretrain_tasks = "wsj"
target_tasks = "wsj"


//train word embeddings from scratch
word_embs = "scratch"

max_grad_norm = 0.25
lr = 3.75
sent_enc = "onlstm"
d_hid = 1150
chunk_size = 10
n_layers_enc = 3
dropconnect = 0.45
dropouti = 0.3
dropout = 0.3
dropouth = 0.5
d_word = 400
max_seq_len = 100
skip_embs = 0
sent_enc = onlstm
batch_size = 20
optimizer = sgd

JIANT_DATA_DIR="/scratch/am8676/exps/anhad_jiant/jiant/data"
FASTTEXT_MODEL_FILE=""
project_dir = "/scratch/am8676/exps/rjiant/jiant/pdir"
word_embs_file = ""
elmo=0
weighting_method="uniform"
scaling_method="max_inverse"
do_pretrain = 0 // Train the shared sentence encoder model (and task-specific model parameters) on the pretraining tasks in
              // pretrain_tasks.
do_target_task_training = 0  // After do_pretrain, train the task-specific model parameters on the target tasks in target_tasks.
do_full_eval = 1     // Evaluate the model on the tasks on target_tasks.
exp_name = wsj_baseVV
#Toronto_14m_validIN/test1_1.0# Toronto_14m_validIN/test1_1.0/log.log  #wmt17_mnlilm/test1_adam_0.005, wmt17/test1_adam_0.005/log.log , BIG_LM_plusMNLI_LM_newvalid/test1_1.0
max_seq_len=100
run_name = test_record

